{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### to do list\n",
    "# 1. Bet --- DONE\n",
    "# 2. Volume Removal ---- DONE\n",
    "# 3. Reallignment ---- DONE\n",
    "# 4. SliceTime Correction\n",
    "# 5. Coregistration --- DONE\n",
    "# 6. Segmentation ---- DONE\n",
    "# 7. Warping  ---- DONE\n",
    "# 8. Smoothing ---- DONE\n",
    "# 9. ART removal ---- DONE\n",
    "# 10. First Level\n",
    "# 11. Flame\n",
    "# 12. Datagrabber  ---- DONE\n",
    "# 13. Datasink     ---- DONE\n",
    "\n",
    "# 14. You need to find a way to draw the subject info data\n",
    "# 15. You need to find a way to substitute contrast manager\n",
    "#https://github.com/niflows/nipype1-workflows/blob/master/package/niflow/nipype1/workflows/fmri/fsl/estimate.py#L141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paradeisios/anaconda3/lib/python3.8/site-packages/nilearn/glm/__init__.py:55: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  warn('The nilearn.glm module is experimental. '\n"
     ]
    }
   ],
   "source": [
    "from nipype import Node, Workflow, IdentityInterface, Function\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces.io import  SelectFiles, DataSink\n",
    "from nipype.algorithms import modelgen, rapidart\n",
    "\n",
    "import nilearn\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "\n",
    "import os \n",
    "import numpy as np\n",
    "\n",
    "mni = \"/usr/local/fsl/data/standard/MNI152_T1_2mm.nii.gz\" # substitute with your mni whole brain template\n",
    "mni_brain = \"/usr/local/fsl/data/standard/MNI152_T1_2mm_brain.nii.gz\" # substitute with your mni extracted brain\n",
    "\n",
    "\n",
    "data_dir  = \"/home/paradeisios/Desktop/pipeline_comparison/data/\" # substitute with your data dir\n",
    "output_dir   = \"/home/paradeisios/Desktop/pipeline_comparison/fsl/\" # substitute with your output dir\n",
    "subject_list = [\"2\"] # substitute with the number of subjects you have\n",
    "\n",
    "names = [\"listening\" for _ in range(7)]\n",
    "onsets = [42,126,210,294,378,462,546]\n",
    "durations = [42 for _ in range(7)]\n",
    "\n",
    "contrasts = {\"Listening>Rest\": [1],\n",
    "             \"Rest>Listening\": [-1]}\n",
    "\n",
    "\n",
    "n_scans=79\n",
    "TR=7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_design_matrix(n_scans,TR,trial_type,onset,duration,motion_regressors):\n",
    "\n",
    "    from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "    from nilearn.plotting import plot_design_matrix\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    \"\"\"A function that creates the first level, subject GLM model\n",
    "       Inputs: trial type(list)  ---> A list with the names of each onset\n",
    "               onset(list)       ---> A list of the onsets of the various condition onsets\n",
    "               duration(list)    ---> A list of the onsets of the various condition durations\n",
    "               motion_regressors ---> A txt file with the realignment parameters\"\"\"\n",
    "    \n",
    "    frame_times = np.arange(n_scans) * TR\n",
    "    motpar = np.loadtxt(motion_regressors, dtype='f')\n",
    "    \n",
    "    events = pd.DataFrame({'trial_type': trial_type, \n",
    "                           'onset': onset,\n",
    "                           'duration': duration})\n",
    "    \n",
    "    matrix = make_first_level_design_matrix(frame_times, \n",
    "                                          events, \n",
    "                                          drift_model=None,\n",
    "                                          add_regs=motpar,  \n",
    "                                          hrf_model='spm')\n",
    "    \n",
    "    plot_design_matrix(matrix,output_file=\"desmat.png\")\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "def fit_first_level_model(functional_scans,matrix):\n",
    "    \n",
    "    from nilearn.glm.first_level import FirstLevelModel\n",
    "    model = FirstLevelModel(minimize_memory=False).fit(functional_scans, design_matrices=matrix)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def estimate_contrasts(fmri_model,matrix,contrast_dictionary):\n",
    "    \n",
    "    from nilearn import plotting\n",
    "    import numpy as np\n",
    "    \n",
    "    \"\"\"Example contrast dict: {\"Active>Passive\":[1,-1],\n",
    "                               \"Passive>Active\":[-1,1]}\"\"\"\n",
    "    \n",
    "    regressor_length = matrix.shape[1]\n",
    "    \n",
    "    for index, (contrast_id, contrast_val) in enumerate(contrast_dictionary.items()):\n",
    "        \n",
    "        contrast = np.hstack((contrast_val, np.zeros(regressor_length - len(contrast_val))))\n",
    "        print(f\"Computing contrast: {contrast_id}, {contrast}\")\n",
    "        \n",
    "        z_map = fmri_model.compute_contrast(contrast, output_type=\"z_score\").to_filename(f\"{contrast_id}_z_map.nii.gz\")\n",
    "        t_map = fmri_model.compute_contrast(contrast, output_type=\"stat\").to_filename(f\"{contrast_id}_t_map.nii.gz\")\n",
    "        \n",
    "\n",
    "        return z_map,t_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data grabber and data deposit\n",
    "\n",
    "\n",
    "# Iterator - this loops though the subject your list provided in cell[2] - if you do not use standard bids, might need modification\n",
    "infosource = Node(IdentityInterface(fields = [\"subject_id\"]),name=\"infosource\")\n",
    "infosource.iterables = [(\"subject_id\", subject_list)]\n",
    "\n",
    "\n",
    "# String template with {}-based strings - this is the DATA GRABBER - you have to provide a template as to how the data are organized in the data folder, so it can find the anatomical and the funcitonal scans\n",
    "template = { \"anat\": data_dir  + \"sub-{subject_id}/anat/T1_w.nii\",\n",
    "             \"func\": data_dir  + \"sub-{subject_id}/func/T2_w.nii\"}\n",
    "\n",
    "selectfiles = Node(SelectFiles(template),name='selectfiles')\n",
    "\n",
    "# Data sink - this is the handler where your data will be output --- IF YOU DO NOT SPECIFY WHICH DATA YOU WANT TO BE SAVED, THEY WILL NOT BE SAVED (this is already done in the workflow, you can change it to add more or less saved outputs)\n",
    "\n",
    "datasink = Node(DataSink(),name=\"datasink\")\n",
    "datasink.inputs.base_directory = output_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##structural workflow\n",
    "\n",
    "bet = Node(fsl.BET(),name=\"bet\")\n",
    "bet.inputs.frac = 0.3 #value controlling how much of the skull to be removed - increasing might remove bits of brain\n",
    "bet.inputs.vertical_gradient = 0.2 #value to linearly improve estimations at the bottom of the brain -increasing might understimate top\n",
    "bet.inputs.mask = True #creates a binary mask of the brain\n",
    "\n",
    "\n",
    "segment = Node(fsl.FAST(),name=\"segment\")\n",
    "\"\"\"You are interested mainly in the restored version of the structural and \n",
    "    pve0 = grey matter\n",
    "    pve1 = white matter\n",
    "    pve2 = CSF \"\"\"\n",
    "segment.inputs.img_type = 1 # indicate its a T1 image\n",
    "segment.inputs.number_classes = 3 # seperate structural into Grey Matter, White Matter and CSF\n",
    "segment.inputs.output_biascorrected = True #return structural image bias field corrected\n",
    "segment.inputs.output_biasfield = True #return bias field\n",
    "segment.inputs.segments=True #create a binary mask for each tissue type\n",
    "segment.inputs.no_pve=False #if you dont want partial volume estimation, set to true\n",
    "\n",
    "\n",
    "flirt_struct = Node(fsl.FLIRT(),name=\"flirt_struct\")\n",
    "\"\"\"This step performs linear registration of the structural volume to the standard space\"\"\"\n",
    "flirt_struct.inputs.reference = mni_brain \n",
    "flirt_struct.inputs.dof = 12 #use 12 dof in structural flirt to prepare image for FNIRT nonlinear normalization to mni space\n",
    "flirt_struct.inputs.out_matrix_file = \"h2s_affine.mat\" #keep this to facilite struct and func normalization to mni space using FNIRT\n",
    "flirt_struct.inputs.interp = \"spline\" # change to trilinear if you are mostly interested in non-subcortical normalization. Trilinear is faster, but might have some rotational issues\n",
    "flirt_struct.inputs.cost = \"mutualinfo\"\n",
    "\n",
    "\n",
    "fnirt_struct = Node(fsl.FNIRT(),name=\"fnirt_struct\")\n",
    "\"\"\"This step performs non-linear registration of the structural volume to the standard space\"\"\"\n",
    "fnirt_struct.inputs.ref_file = mni\n",
    "fnirt_struct.inputs.config_file = \"T1_2_MNI152_2mm\"\n",
    "fnirt_struct.inputs.fieldcoeff_file = True  #keep the deformation fields to faciliate func normalization with FNIRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##functional workflow\n",
    "img_to_float = Node(fsl.ImageMaths(),name=\"img_to_float\")\n",
    "\"\"\"This converts the 4d in float representation to faciliate some further computations\"\"\"\n",
    "img_to_float.inputs.out_data_type='float'\n",
    "img_to_float.inputs.op_string=''\n",
    "\n",
    "\n",
    "vol_removal = Node(fsl.ExtractROI(), name=\"vol_removal\")\n",
    "\"\"\"This step removes the 5 first volumes to avoid T1 saturation\"\"\"\n",
    "vol_removal.inputs.t_min = 5 #number of scans to exclude from functional image\n",
    "vol_removal.inputs.t_size = -1 # keep all the rest until the end\n",
    "\n",
    "\n",
    "realign = Node(fsl.MCFLIRT(),name = \"realign\")\n",
    "\"\"\"This step realigns data to the first image\"\"\" \n",
    "realign.inputs.save_mats = True #save realignment  parameters\n",
    "realign.inputs.save_plots = True #save parameter plots\n",
    "realign.inputs.dof = 6 #use this for rigid body correction\n",
    "\n",
    "\n",
    "art = Node(rapidart.ArtifactDetect(),name=\"art\")\n",
    "\"\"\"This step performs artifact detection\"\"\" \n",
    "art.inputs.mask_type = \"spm_global\"\n",
    "art.inputs.parameter_source = 'FSL'\n",
    "art.inputs.norm_threshold = 1\n",
    "art.inputs.use_differences = [True, False]\n",
    "art.inputs.zintensity_threshold = 3\n",
    "\n",
    "\n",
    "mean_img = Node(fsl.maths.MeanImage(),name= \"mean_img\")\n",
    "mean_img.inputs.dimension = \"T\" # find mean image across the time dimension\n",
    "\n",
    "\n",
    "flirt_func = Node(fsl.FLIRT(),name = \"flirt_func\")\n",
    "\"\"\"This step performs linear registration of the functional volume to the structural volume. It is mainly used to\n",
    "extract the transformation matrix to later register to standard space\"\"\"\n",
    "flirt_func.inputs.dof = 6\n",
    "flirt_func.inputs.out_matrix_file = \"f2h_affine.mat\"\n",
    "flirt_func.inputs.interp = \"spline\"\n",
    "flirt_func.inputs.cost = \"mutualinfo\"\n",
    "\n",
    "\n",
    "func_warp = Node(fsl.ApplyWarp(),name = \"func_warp\")\n",
    "\"\"\"This step performs non linear registration to standard space using the affine matrix extracted \n",
    "in the flirt above and the fnirt non linear warp in the structural pipeline \"\"\"\n",
    "func_warp.inputs.ref_file = mni\n",
    "\n",
    "\n",
    "smooth = Node(fsl.IsotropicSmooth(),name=\"smooth\")\n",
    "\"\"\"This step performs smoothing\"\"\"\n",
    "smooth.inputs.fwhm = 6 #change the smoothing kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_matrix = Node(Function(input_names=[\"n_scans\",\"TR\",\"trial_type\",\"onset\",\"duration\",\"motion_regressors\"], \n",
    "                              output_names=[\"matrix\"], \n",
    "                              function=create_design_matrix), \n",
    "                              name='design_matrix')\n",
    "\n",
    "design_matrix.inputs.n_scans = n_scans\n",
    "design_matrix.inputs.TR = TR\n",
    "design_matrix.inputs.trial_type = names\n",
    "design_matrix.inputs.onset = onsets\n",
    "design_matrix.inputs.duration = durations\n",
    "\n",
    "\n",
    "first_level_fit = Node(Function(input_names=[\"functional_scans\",\"matrix\"],\n",
    "                                  output_names=[\"model\"],\n",
    "                                  function=fit_first_level_model),\n",
    "                                  name=\"first_level_fit\")\n",
    "\n",
    "contrast_estimation = Node(Function(inputs_names=[\"fmri_model\",\"matrix\",\"contrast_dictionary\"],\n",
    "                                   output_names=[\"z_map,t_map\"],\n",
    "                                   function=estimate_contrasts),\n",
    "                                   name=\"contrast_estimation\")\n",
    "\n",
    "contrast_estimation.inputs.contrast_dictionary= contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_flow = Workflow(name=\"struct_flow\", base_dir=output_dir)\n",
    "struct_flow.connect(bet,\"out_file\",segment,\"in_files\")\n",
    "struct_flow.connect(segment,\"restored_image\",flirt_struct,\"in_file\")\n",
    "struct_flow.connect(flirt_struct,\"out_matrix_file\",fnirt_struct,\"affine_file\")\n",
    "\n",
    "#########################################################################################################\n",
    "func_flow = Workflow(name=\"func_flow\", base_dir=output_dir)\n",
    "func_flow.connect(img_to_float,\"out_file\",vol_removal,\"in_file\")\n",
    "func_flow.connect(vol_removal, \"roi_file\", realign, \"in_file\")\n",
    "func_flow.connect(realign,\"out_file\",art,\"realigned_files\")\n",
    "func_flow.connect(realign,\"par_file\",art,\"realignment_parameters\")\n",
    "func_flow.connect(realign,\"out_file\",mean_img,\"in_file\")\n",
    "func_flow.connect(mean_img,\"out_file\",flirt_func,\"in_file\")\n",
    "func_flow.connect(flirt_func,\"out_matrix_file\",func_warp,\"premat\")\n",
    "func_flow.connect(realign,\"out_file\",func_warp,\"in_file\")\n",
    "func_flow.connect(func_warp,\"out_file\",smooth,\"in_file\")\n",
    "\n",
    "#######################################################################################################\n",
    "first_level_flow = Workflow(name=\"first_level_flow\",base_dir=output_dir)\n",
    "first_level_flow.connect(design_matrix,\"matrix\",first_level_fit,\"matrix\")\n",
    "first_level_flow.connect(first_level_fit,\"model\",contrast_estimation,\"fmri_model\")\n",
    "first_level_flow.connect(design_matrix,\"matrix\",contrast_estimation,\"matrix\")\n",
    "\n",
    "########################################################################################################\n",
    "\n",
    "analysis_flow = Workflow(name=\"analysis_flow\",base_dir=output_dir)\n",
    "\n",
    "analysis_flow.connect([(infosource,selectfiles,[(\"subject_id\",\"subject_id\")]),\n",
    "                         (selectfiles,struct_flow,[(\"anat\",\"bet.in_file\")]),\n",
    "                         (selectfiles,struct_flow,[(\"anat\",\"fnirt_struct.in_file\")]),\n",
    "                         (selectfiles,func_flow,[(\"func\",\"img_to_float.in_file\")]),                                                   \n",
    "                         (struct_flow,func_flow,[(\"segment.restored_image\",\"flirt_func.reference\")]),\n",
    "                         (struct_flow,func_flow,[(\"fnirt_struct.fieldcoeff_file\",\"func_warp.field_file\")]),\n",
    "                         (func_flow,first_level_flow,[(\"smooth.out_file\",\"first_level_fit.functional_scans\")]),\n",
    "                         (func_flow,first_level_flow,[(\"realign.par_file\",\"design_matrix.motion_regressors\")])])\n",
    "\n",
    "#######################################################################################################\n",
    "\n",
    "#this is your datasink, where you stash the results you want\n",
    "\n",
    "analysis_flow.connect([(infosource,datasink,[(\"subject_id\", \"container\")]),\n",
    "                         #########################################################################\n",
    "                         (struct_flow,datasink,[(\"bet.out_file\",\"bet.@bet_brain\")]),\n",
    "                         (struct_flow,datasink,[(\"bet.mask_file\",\"bet.@bet_mask\")]),\n",
    "                         (struct_flow,datasink,[(\"segment.restored_image\",\"segment.@restored_image\")]),\n",
    "                         (struct_flow,datasink,[(\"segment.tissue_class_files\",\"segment.@tissue_class_files\")]),\n",
    "                         (struct_flow,datasink,[(\"segment.bias_field\",\"segment.@bias_field\")]),\n",
    "                         (struct_flow,datasink,[(\"segment.tissue_class_map\",\"segment.@tissue_class_map\")]),\n",
    "                         (struct_flow,datasink,[(\"flirt_struct.out_file\",\"flirt_struct.@structural_flirt\")]),\n",
    "                         (struct_flow,datasink,[(\"flirt_struct.out_matrix_file\",\"flirt_struct.@affine_parameters\")]),\n",
    "                         (struct_flow,datasink,[(\"fnirt_struct.warped_file\",\"flirt_struct.@structural_fnirt\")]),\n",
    "                         (struct_flow,datasink,[(\"fnirt_struct.field_file\",\"flirt_struct.@fieldcoeff_file\")]),\n",
    "                         \n",
    "                         #########################################################################\n",
    "                         (func_flow,datasink,[(\"vol_removal.roi_file\",\"vol_removal.@files\")]),\n",
    "                         (func_flow,datasink,[(\"realign.out_file\",\"realign.@realigned_files\")]),\n",
    "                         (func_flow,datasink,[(\"realign.par_file\",\"realign.@realig_parameters\")]),\n",
    "                         (func_flow,datasink,[(\"art.outlier_files\",\"art.@outlier_files\")]),\n",
    "                         (func_flow,datasink,[(\"art.plot_files\",\"art.@plot_files\")]),\n",
    "                         (func_flow,datasink,[(\"art.displacement_files\",\"art.@displacement_files\")]),\n",
    "                         (func_flow,datasink,[(\"mean_img.out_file\",\"mean_img.@mean_img\")]),\n",
    "                         (func_flow,datasink,[(\"flirt_func.out_matrix_file\",\"flirt_func.@affine_parameters\")]),\n",
    "                         (func_flow,datasink,[(\"flirt_func.out_file\",\"flirt_func.@functional_flirt\")]),\n",
    "                         (func_flow,datasink,[(\"func_warp.out_file\",\"func_warp.@functional_fnirt\")]),\n",
    "                         (func_flow,datasink,[(\"smooth.out_file\",\"smooth.@smoothed_files\")])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210511-12:45:39,265 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /home/paradeisios/Desktop/pipeline_comparison/fsl/analysis_flow/workflow_graph.png (graph2use=hierarchical, simple_form=True).\n",
      "210511-12:45:40,449 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /home/paradeisios/Desktop/pipeline_comparison/fsl/analysis_flow/graph.png (graph2use=colored, simple_form=True).\n",
      "210511-12:45:47,832 nipype.workflow INFO:\n",
      "\t Generated workflow graph: /home/paradeisios/Desktop/pipeline_comparison/fsl/analysis_flow/graph.png (graph2use=flat, simple_form=True).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/paradeisios/Desktop/pipeline_comparison/fsl/analysis_flow/graph.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_flow.write_graph(\"workflow_graph.dot\")\n",
    "\n",
    "analysis_flow.write_graph(graph2use='colored')\n",
    "analysis_flow.write_graph(graph2use='flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210511-12:45:47,870 nipype.workflow INFO:\n",
      "\t Workflow analysis_flow settings: ['check', 'execution', 'logging', 'monitoring']\n",
      "210511-12:45:47,886 nipype.workflow INFO:\n",
      "\t Running in parallel.\n",
      "210511-12:45:47,890 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 13.79/13.79, Free processors: 4/4.\n",
      "210511-12:45:47,977 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"analysis_flow.selectfiles\" in \"/home/paradeisios/Desktop/pipeline_comparison/fsl/analysis_flow/_subject_id_2/selectfiles\".\n",
      "210511-12:45:47,983 nipype.workflow INFO:\n",
      "\t [Node] Running \"selectfiles\" (\"nipype.interfaces.io.SelectFiles\")\n",
      "210511-12:45:47,991 nipype.workflow INFO:\n",
      "\t [Node] Finished \"analysis_flow.selectfiles\".\n",
      "210511-12:45:49,893 nipype.workflow INFO:\n",
      "\t [Job 0] Completed (analysis_flow.selectfiles).\n",
      "210511-12:45:49,898 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 13.79/13.79, Free processors: 4/4.\n",
      "210511-12:45:49,986 nipype.workflow INFO:\n",
      "\t [Job 1] Cached (analysis_flow.func_flow.img_to_float).\n",
      "210511-12:45:49,989 nipype.workflow INFO:\n",
      "\t [Job 7] Cached (analysis_flow.struct_flow.bet).\n",
      "210511-12:45:51,948 nipype.workflow INFO:\n",
      "\t [Job 2] Cached (analysis_flow.func_flow.vol_removal).\n",
      "210511-12:45:51,952 nipype.workflow INFO:\n",
      "\t [Job 8] Cached (analysis_flow.struct_flow.segment).\n",
      "210511-12:45:53,961 nipype.workflow INFO:\n",
      "\t [Job 3] Cached (analysis_flow.func_flow.realign).\n",
      "210511-12:45:53,966 nipype.workflow INFO:\n",
      "\t [Job 10] Cached (analysis_flow.struct_flow.flirt_struct).\n",
      "210511-12:45:55,902 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 4 jobs ready. Free memory (GB): 13.79/13.79, Free processors: 4/4.\n",
      "210511-12:45:55,985 nipype.workflow INFO:\n",
      "\t [Job 4] Cached (analysis_flow.first_level_flow.design_matrix).\n",
      "210511-12:45:55,990 nipype.workflow INFO:\n",
      "\t [Job 5] Cached (analysis_flow.func_flow.mean_img).\n",
      "210511-12:45:55,994 nipype.workflow INFO:\n",
      "\t [Job 6] Cached (analysis_flow.func_flow.art).\n",
      "210511-12:45:55,999 nipype.workflow INFO:\n",
      "\t [Job 11] Cached (analysis_flow.struct_flow.fnirt_struct).\n",
      "210511-12:45:57,904 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 13.79/13.79, Free processors: 4/4.\n",
      "210511-12:45:57,989 nipype.workflow INFO:\n",
      "\t [Job 9] Cached (analysis_flow.func_flow.flirt_func).\n",
      "210511-12:45:59,988 nipype.workflow INFO:\n",
      "\t [Job 12] Cached (analysis_flow.func_flow.func_warp).\n",
      "210511-12:46:01,980 nipype.workflow INFO:\n",
      "\t [Job 13] Cached (analysis_flow.func_flow.smooth).\n",
      "210511-12:46:03,910 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 2 jobs ready. Free memory (GB): 13.79/13.79, Free processors: 4/4.\n",
      "210511-12:46:04,21 nipype.workflow INFO:\n",
      "\t [Job 14] Cached (analysis_flow.first_level_flow.first_level_fit).\n",
      "210511-12:46:04,40 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"analysis_flow.datasink\" in \"/home/paradeisios/Desktop/pipeline_comparison/fsl/analysis_flow/_subject_id_2/datasink\".\n",
      "210511-12:46:04,49 nipype.workflow INFO:\n",
      "\t [Node] Running \"datasink\" (\"nipype.interfaces.io.DataSink\")\n",
      "210511-12:46:04,60 nipype.workflow INFO:\n",
      "\t [Node] Finished \"analysis_flow.datasink\".\n",
      "210511-12:46:05,910 nipype.workflow INFO:\n",
      "\t [Job 16] Completed (analysis_flow.datasink).\n",
      "210511-12:46:05,919 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 0 tasks, and 1 jobs ready. Free memory (GB): 13.79/13.79, Free processors: 4/4.\n",
      "210511-12:46:06,7 nipype.workflow INFO:\n",
      "\t [Node] Setting-up \"analysis_flow.first_level_flow.contrast_estimation\" in \"/home/paradeisios/Desktop/pipeline_comparison/fsl/analysis_flow/first_level_flow/_subject_id_2/contrast_estimation\".\n",
      "210511-12:46:07,909 nipype.workflow INFO:\n",
      "\t [MultiProc] Running 1 tasks, and 0 jobs ready. Free memory (GB): 13.59/13.79, Free processors: 3/4.\n",
      "                     Currently running:\n",
      "                       * analysis_flow.first_level_flow.contrast_estimation\n"
     ]
    }
   ],
   "source": [
    "analysis_flow.run(plugin='MultiProc', plugin_args={'n_procs' : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
